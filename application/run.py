import boto3
import os
from utils.evalution_criteria import calculate_sharpe_ratio,check_required_columns
from utils.runtime_checks import run_script
from utils.static_checks import perform_static_checks
from utils.replace_func import update_script_with_template_functions,replace_main_block
from utils.boto3_helper import store_sharpe_ratio_in_dynamodb,send_failure_email,upload_script_to_s3,download_from_s3,upload_weights_to_s3
import logging
import re

USER_SCRIPTS_BUCKET_NAME = os.environ.get("USER_SCRIPTS_BUCKET_NAME", "jkpfactors-user-scripts")
INTEGRITY_CHECK_DATA_S3_URI = os.environ.get("INTEGRITY_CHECK_DATA_S3_URI","s3://jkpfactors-training-data/integrity-check/2024/")
INTEGRITY_CHECK_DATA_LOCAL_PATH = os.environ.get("INTEGRITY_CHECK_DATA_LOCAL_PATH","integrity-check/")
COMPLETE_DATA_S3_URI = os.environ.get("COMPLETE_DATA_S3_URI","s3://jkpfactors-training-data/complete/2024/")
COMPLETE_DATA_PATH = os.environ.get("COMPLETE_DATA_PATH","data/")
SHOULD_PERFORM_COMPLETE_TRAINING = os.environ.get("SHOULD_PERFORM_COMPLETE_TRAINING","False")=="True"
SHOULD_PERFORM_INTEGRITY_CHECK = os.environ.get("SHOULD_PERFORM_INTEGRITY_CHECK","True")=="True"
AWS_DEFAULT_REGION = os.environ.get("AWS_DEFAULT_REGION","us-east-1")
RETRAIN = os.environ.get("RETRAIN","False")=="True"

logging.getLogger().setLevel(logging.DEBUG)

def decode_file(file_name):
    # Read the string representation of the code from the input file
    with open(file_name, 'r') as file:
        code_str = file.read()

    # Remove the leading and trailing quotes if they exist
    if code_str.startswith('"') and code_str.endswith('"'):
        code_str = code_str[1:-1]

    # Convert common escape sequences
    normal_code = code_str.replace(r'\r\n', '\n').replace(r'\n', '\n').replace(r'\/', '/').replace(r'\t', '\t').encode().decode('unicode_escape')

    # Write the converted code to the output file
    with open(file_name, 'w') as file:
        file.write(normal_code)

    logging.info(f"The file has been successfully decoded to {file_name}")
            
def perform_integrity_check(script_file, output_file):
    
    # Step 1: Static Checks
    is_valid, message = perform_static_checks(script_file)
    if not is_valid:
        return False, message
    
    # Step 2: Check the output csv if it contains all required columns.
    is_valid, message = check_required_columns(output_file)
    if not is_valid:
        return False, message

    is_valid, message = compare_columns(output_file)
    # Step 3: Runtime Checks
    template_functions_mapping = {
        'load_data': 'templates/integrity_check/load_func.py',
        'export_data': 'templates/integrity_check/export_func.py',
    }
    update_script_with_template_functions(script_file,template_functions_mapping)
    main_block_template_path = "templates/integrity_check/main_block.py"
    replace_main_block(script_file, main_block_template_path)

    # Step 4: replace data loading and export function in the script file
    is_valid, message = run_script(script_file)
    if not is_valid:
        return False, message
    
    # Step 4: Check the output csv generated by script if it contains all required columns.
    is_valid, message = check_required_columns("integrity-check/training_results.csv")
    if not is_valid:
        return False, message

    return True, "All checks passed"

def main(user_ml_script_s3_uri, user_ml_output_csv_s3_uri,submission_timestamp,email,user_name,model_name):
    # Define local paths
    script_file = user_ml_script_s3_uri.split("/")[-1]
    output_file = user_ml_output_csv_s3_uri.split("/")[-1]
    
    # Download the files from S3
    download_from_s3(user_ml_script_s3_uri, script_file)
    decode_file(script_file)
    download_from_s3(user_ml_output_csv_s3_uri, output_file)
    decode_file(output_file)
    
    
    is_valid = True

    if SHOULD_PERFORM_INTEGRITY_CHECK:
        download_from_s3(INTEGRITY_CHECK_DATA_S3_URI,INTEGRITY_CHECK_DATA_LOCAL_PATH)
        download_from_s3(COMPLETE_DATA_S3_URI,COMPLETE_DATA_PATH)
        # Run integrity checks
        is_valid, message = perform_integrity_check(script_file, output_file)
        print(message)
        
        if is_valid:
            upload_script_to_s3(script_file,output_file,USER_SCRIPTS_BUCKET_NAME,email,submission_timestamp)
        else:
            send_failure_email(email=email,message=message)


    if is_valid and SHOULD_PERFORM_COMPLETE_TRAINING:
        
        # Step 1: Replace data loading and export function in the script file
        download_from_s3(COMPLETE_DATA_S3_URI,COMPLETE_DATA_PATH)
        
        # Step 2: Replace data loading and export function in the script file
        template_functions_mapping = {
            'load_data': 'templates/complete_data/load_func.py',
            'export_data': 'templates/complete_data/export_func.py',
        }
        update_script_with_template_functions(script_file,template_functions_mapping)
        # Replace the main block
        main_block_template_path = "templates/complete_data/main_block.py"
        replace_main_block(script_file, main_block_template_path)

        # Step 3: Run the downloaded script
        is_valid, message = run_script(script_file)
        if not is_valid:
            return False, message
        
        # Step 4: Check output columns
        is_valid, message = check_required_columns("data/training_results.csv")
        if not is_valid:
            return False, message
        
        # Step 5: Evaluation Criteria
        is_valid, message = calculate_sharpe_ratio()
        if not is_valid:
            return False, message
            
        upload_weights_to_s3(USER_SCRIPTS_BUCKET_NAME,email,submission_timestamp)
        update_submissions_dynamodb(email, submission_timestamp, script_file, output_file, RETRAIN ,message)
        store_sharpe_ratio_in_dynamodb(sharpe_ratio=message,submission_timestamp=submission_timestamp,email=email,user_name=user_name,model_name=model_name,retrain=RETRAIN)
            

if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description='Run integrity checks and execute user ML script.')
    parser.add_argument('--user_ml_script_s3_uri', type=str, help='The S3 URI of the user ML script.')
    parser.add_argument('--user_ml_output_csv_s3_uri', type=str, help='The S3 URI of the user ML output CSV.')
    parser.add_argument('--submission_timestamp', type=str, help='The S3 URI of the user ML output CSV.')
    parser.add_argument('--email', type=str, help='The S3 URI of the user ML output CSV.')
    parser.add_argument('--user_name', type=str, help='The S3 URI of the user ML output CSV.')
    parser.add_argument('--model_name', type=str, help='The S3 URI of the user ML output CSV.')

    args = parser.parse_args()
    main(args.user_ml_script_s3_uri, args.user_ml_output_csv_s3_uri,args.submission_timestamp,args.email,args.user_name,args.model_name)